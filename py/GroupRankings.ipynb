{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    NamedTuple,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Any,\n",
    "    Dict,\n",
    "    Union,\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Sequence,\n",
    ")\n",
    "\n",
    "import rich.panel\n",
    "import sklearn.base\n",
    "from alive_progress import alive_bar\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from log_symbols import LogSymbols\n",
    "\n",
    "import overrides as overrides\n",
    "import pandas as pds\n",
    "import tabulate as tabulate\n",
    "from collections import namedtuple\n",
    "from sklearn import linear_model, metrics, preprocessing, model_selection, svm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from halo import Halo\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn import neural_network, tree\n",
    "from sklearn.model_selection import (\n",
    "    HalvingGridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingRandomSearchCV,\n",
    ")\n",
    "import scipy.stats as scistats\n",
    "\n",
    "import rich.progress\n",
    "import commons\n",
    "from data_types import PickleOut\n",
    "from rich.traceback import install as niceTracebacks\n",
    "from rich.table import Table as rTable\n",
    "\n",
    "from db_actions import db_actions\n",
    "import numpy as np\n",
    "\n",
    "from linRegPred import getSplits, getTransformers\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import r2_score\n",
    "import textdistance as TD\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    dF = pds.read_sql('SELECT * FROM \"runtimeScorePredBase1000\"', conn)\n",
    "# print(dF)\n",
    "all_x_cols = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\",\n",
    "        \"pCpu\",\n",
    "        \"cpus\",\n",
    "        \"rss\",\n",
    "        \"vmem\",\n",
    "        \"rchar\",\n",
    "        \"wchar\",\n",
    "        \"syscr\",\n",
    "        \"syscw\",\n",
    "]\n",
    "filtered_x_cols = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21',\n",
    "                   'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr',\n",
    "                   'syscw']\n",
    "x_cols = all_x_cols\n",
    "y_cols = \"realtime\"\n",
    "\n",
    "X: pds.DataFrame = dF[x_cols]\n",
    "y: pds.DataFrame = dF[y_cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from my_yaml import yaml_load\n",
    "\n",
    "with open(\"nodeConfigIdLookup.yaml\", \"r\") as f:\n",
    "    t = yaml_load(f)\n",
    "    nodeIDLUT = {v: k for k, v in t.items()}\n",
    "dF[\"nodeName\"] = dF[\"nodeConfig\"].transform(lambda x: nodeIDLUT[x])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "awsGroupLUT = {\n",
    "        \"general\": [\"M7g\", \"Mac\", \"M6g\", \"M6i\", \"M6in\", \"M6a\", \"M5\", \"M5n\", \"M5zn\", \"M5a\", \"M4\", \"A1\", \"T4g\", \"T3\",\n",
    "                    \"T3a\",\n",
    "                    \"T2\"],\n",
    "        \"compute\": [\"C7g\", \"C7gn\", \"C6i\", \"C6in\", \"C6a\", \"C6g\", \"C6gn\", \"C5\", \"C5n\", \"C5a\", \"C4\"],\n",
    "        \"memory\": [\"R7g\", \"R7iz\", \"R6g\", \"R6i\", \"R6in\", \"R6a\", \"R5\", \"R5n\", \"R5b\", \"R5a\", \"R4\", \"X2gd\", \"X2idn\",\n",
    "                   \"X2iedn\",\n",
    "                   \"X2iezn\", \"X1\", \"X1e\", \"z1d\"],\n",
    "        \"accelerated\": [\"P4\", \"P3\", \"P2\", \"DL1\", \"Trn1\", \"Inf2\", \"Inf1\", \"G5\", \"G5g\", \"G4dn\", \"G4ad\", \"G3\", \"F1\",\n",
    "                        \"VT1\"],\n",
    "        \"storage\": [\"Im4gn\", \"Is4gen\", \"I4i\", \"I3\", \"I3en\", \"D2\", \"D3\", \"D3en\", \"H1\"],\n",
    "        \"HPC\": [\"Hpc6id\", \"Hpc6a\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "awsInstanceGroupLUT = {i.lower(): k for k, v in awsGroupLUT.items() for i in v}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dF[\"nodeGroup\"] = dF[\"nodeName\"].transform(lambda x: awsInstanceGroupLUT[x.split(\".\")[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "usedAwsGroupLUT = {\n",
    "        k: list(pds.unique(dF.query(\"nodeGroup==@k\").nodeName.values)) for k in awsGroupLUT.keys()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "nodesPerGroup = {\n",
    "        k: len(v) for k, v in usedAwsGroupLUT.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "if False:\n",
    "    #sns.boxplot(data=dF,y=\"realtime\",x=\"taskName\",hue=\"nodeGroup\")\n",
    "    for wf in dF.groupby(by=\"wfName\"):\n",
    "        wfname, data = wf\n",
    "        print(wfname)\n",
    "        grid = sns.FacetGrid(data, row=\"wfName\", col=\"nodeGroup\", sharex=False, sharey=True, margin_titles=True,\n",
    "                             height=5)\n",
    "        grid.map_dataframe(sns.boxplot, y=\"realtime\", x=\"taskName\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find prototypes for each group"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "true_ranks_df = pds.DataFrame()\n",
    "for l, d in dF.groupby(by=[\"wfName\", \"taskName\", \"nodeName\"]):\n",
    "    wn, tn, nn = l\n",
    "    true_ranks_df = true_ranks_df.append(\n",
    "            {\"wfName\": wn, \"taskName\": tn, \"nodeName\": nn, \"realtime\": d.realtime.mean(), \"rank\": 0},\n",
    "            ignore_index=True)\n",
    "\n",
    "for l, d in true_ranks_df.groupby(by=[\"wfName\", \"taskName\"]):\n",
    "    wn, tn = l\n",
    "    ranks = rankdata(d.realtime.values, method=\"min\")\n",
    "    d[\"rank\"] = ranks\n",
    "    true_ranks_df.update(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    scores_df = pds.read_sql('SELECT * FROM \"nodeBenchmarkTransposedScores\"', conn)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "scores_df[\"nodeName\"] = scores_df[\"nodeConfig\"].transform(lambda x: nodeIDLUT[x])\n",
    "scores_df[\"nodeGroup\"] = scores_df[\"nodeName\"].transform(lambda x: awsInstanceGroupLUT[x.split(\".\")[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "groupOrder = [\"general\", \"compute\", \"memory\", \"storage\"]\n",
    "nodeOrder = list(pds.unique(dF.nodeName))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "benchmarkCols = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\"]\n",
    "nodeGroups = [scores_df.query(\"nodeGroup==@gn\").nodeName.values for gn in groupOrder]\n",
    "nodeGroupBenchmarkAverages = [np.average([scores_df.query(\"nodeName==@nn\")[benchmarkCols] for nn in ng], axis=0) for ng\n",
    "                              in nodeGroups]\n",
    "for c in itertools.product(*nodeGroups):\n",
    "    n1, n2, n3, n4 = c\n",
    "    ns1 = scores_df.query(\"nodeName == @n1\")[benchmarkCols].values[0]\n",
    "    ns2 = scores_df.query(\"nodeName == @n2\")[benchmarkCols].values[0]\n",
    "    ns3 = scores_df.query(\"nodeName == @n3\")[benchmarkCols].values[0]\n",
    "    ns4 = scores_df.query(\"nodeName == @n4\")[benchmarkCols].values[0]\n",
    "    distance_between_protos = np.linalg.norm(ns1 - ns2) + np.linalg.norm(ns1 - ns3) + np.linalg.norm(\n",
    "            ns1 - ns4) + np.linalg.norm(ns2 - ns3) + np.linalg.norm(ns2 - ns4) + np.linalg.norm(ns3 - ns4)\n",
    "    distances_from_group_averages = [np.linalg.norm(bs - ngba) for bs, ngba in\n",
    "                                     zip([ns1, ns2, ns3, ns4], nodeGroupBenchmarkAverages)]\n",
    "    scores[c] = (distance_between_protos, np.sum(distances_from_group_averages))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "factor = sum(x[0] for x in scores.values()) / sum(x[1] for x in scores.values())\n",
    "scores = {\n",
    "        k: v[0] + factor * v[1] for k, v in scores.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('m5.xlarge', 'c5.xlarge', 'r5.xlarge', 'i3.2xlarge')\n"
     ]
    }
   ],
   "source": [
    "cs, ds = scores.keys(), scores.values()\n",
    "#print(\"\\n\".join(map(lambda x: repr(x), sorted(zip(cs, ds), key=lambda x: x[1])[:10])))\n",
    "groupPrototypes = sorted(zip(cs, ds), key=lambda x: x[1])[0][0]\n",
    "print(groupPrototypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "bestGroupPrototypes = (\n",
    "        'm5.xlarge', 'c5.xlarge', 'r5.xlarge', 'i3.2xlarge')  # = sorted(zip(cs, ds), key=lambda x: x[1])[0][0]\n",
    "bestGroupPrototypesLUT = {\n",
    "        awsInstanceGroupLUT[k.split(\".\")[0]]: k for k in bestGroupPrototypes\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': 'm5.xlarge', 'compute': 'c5.xlarge', 'memory': 'r5.xlarge', 'storage': 'i3.2xlarge'}\n"
     ]
    }
   ],
   "source": [
    "print(bestGroupPrototypesLUT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Produce Group Rankings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def makeGroupRankings(prototypes):\n",
    "    prototypesLUT = {\n",
    "            awsInstanceGroupLUT[k.split(\".\")[0]]: k for k in prototypes\n",
    "    }\n",
    "    groupPerformances = dict()\n",
    "    for g in dF.groupby(by=[\"nodeGroup\", \"wfName\", \"taskName\"]):\n",
    "        l, d = g\n",
    "        ng, wfn, tn = l\n",
    "        if (wfn, tn) not in groupPerformances.keys():\n",
    "            groupPerformances[(wfn, tn)] = dict()\n",
    "        groupProto = prototypesLUT[ng]\n",
    "        groupPerformances[(wfn, tn)][ng] = d.query(\"nodeName == @groupProto\").realtime.mean()\n",
    "        #groupPerformances[l] = d.realtime.mean()\n",
    "    groupRankings = {\"wfName\": [], \"taskName\": [], **{o: [] for o in groupOrder}}\n",
    "    for k, v in groupPerformances.items():\n",
    "        wfn, tn = k\n",
    "        performances = [v[i] for i in groupOrder]\n",
    "        ranks = rankdata(performances, method=\"min\")\n",
    "        groupRankings[\"wfName\"].append(wfn)\n",
    "        groupRankings[\"taskName\"].append(tn)\n",
    "        for o, r in zip(groupOrder, ranks):\n",
    "            groupRankings[o].append(r)\n",
    "    return pds.DataFrame(groupRankings)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Produce intragroup node rankings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def makeNodeRankingsInGroups(groupRankings):\n",
    "    tmp = pds.DataFrame(\n",
    "            columns=[\"group\", \"nodeName\", \"wfName\", \"taskName\", \"realtime\", \"groupRank\", \"intraGroupRank\", \"globalRank\",\n",
    "                     \"trueRank\"])\n",
    "    tmp2 = {\"group\": [], \"nodeName\": [], \"wfName\": [], \"taskName\": [], \"realtime\": []}\n",
    "    for g in dF.groupby(by=[\"nodeGroup\", \"wfName\", \"taskName\", \"nodeName\"]):\n",
    "        l, d = g\n",
    "        ng, wfn, tn, nn = l\n",
    "        tmp2[\"group\"].append(ng)\n",
    "        tmp2[\"nodeName\"].append(nn)\n",
    "        tmp2[\"wfName\"].append(wfn)\n",
    "        tmp2[\"taskName\"].append(tn)\n",
    "        tmp2[\"realtime\"].append(d.realtime.mean())\n",
    "    tmp = tmp.append(pds.DataFrame(tmp2), ignore_index=True)\n",
    "\n",
    "    for l, d in tmp.groupby([\"group\", \"wfName\", \"taskName\"]):\n",
    "        gr, wfn, tn = l\n",
    "        ra = list(rankdata(d.realtime, method=\"min\"))\n",
    "        cache = groupRankings.query(\"wfName==@wfn and taskName==@tn\")\n",
    "        ar = 0\n",
    "        grr = cache[gr].values[0]\n",
    "        for k, v in sorted(list(zip(groupOrder, (cache[k].values[0] for k in groupOrder))), key=lambda x: x[1]):\n",
    "            if v >= grr:\n",
    "                break\n",
    "            ar += nodesPerGroup[k]\n",
    "        # d[\"intraGroupRank\"] = ra\n",
    "        # d[\"groupRank\"] = [grr] * len(ra)\n",
    "        # d[\"globalRank\"] = np.array([ar] * len(ra)) + np.array(ra)\n",
    "        tmp.update(pds.DataFrame({\"intraGroupRank\": ra, \"groupRank\": [grr] * len(ra),\n",
    "                                  \"globalRank\": np.array([ar] * len(ra)) + np.array(ra)}, index=d.index))\n",
    "\n",
    "    for l, d in tmp.groupby([\"wfName\", \"taskName\"]):\n",
    "        tr = list(rankdata(d.realtime, method=\"min\"))\n",
    "        #d[\"trueRank\"] = tr\n",
    "        tmp.update(pds.DataFrame({\"trueRank\": tr}, index=d.index))\n",
    "\n",
    "    return tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tmp3 = makeNodeRankingsInGroups(makeGroupRankings(bestGroupPrototypes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "export = pds.DataFrame(\n",
    "        {\"wfName\": tmp3.wfName, \"taskName\": tmp3.taskName, \"nodeName\": tmp3.nodeName, \"rank\": tmp3.globalRank})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "export.to_csv(\"no_ML_ranks.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "scores = []\n",
    "for l, d in tmp3.groupby(by=[\"wfName\", \"taskName\"]):\n",
    "    scores.append(commons.rankingScore(d.globalRank.values, d.trueRank.values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def scoreRankings(ranking_df):\n",
    "    scores = []\n",
    "    for l, d in ranking_df.groupby(by=[\"wfName\", \"taskName\"]):\n",
    "        scores.append(commons.rankingScore(d.globalRank.values, d.trueRank.values))\n",
    "    return np.average(scores), np.std(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7774478651178136, 0.043526414580650014)\n"
     ]
    }
   ],
   "source": [
    "print(scoreRankings(tmp3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bruteforce test all prototype selections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def do_one(x):\n",
    "    return x, scoreRankings(makeNodeRankingsInGroups(makeGroupRankings(x)))\n",
    "\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = pool.map(do_one, itertools.product(*nodeGroups))\n",
    "    prototypeSelectionScores = {c: r for c, r in results}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('m5.large', 'c5.2xlarge', 'r5.large', 'i3.large'), (0.7795315240228508, 0.045679419955128885)), (('m5.xlarge', 'c5a.xlarge', 'r5.xlarge', 'i3.xlarge'), (0.7792537028355125, 0.04079461900066024)), (('m5.large', 'c5.2xlarge', 'r5.large', 'i3.xlarge'), (0.7790106092965915, 0.04536687791506502))]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(zip(prototypeSelectionScores.keys(), prototypeSelectionScores.values()),\n",
    "             key=lambda x: prototypeSelectionScores[x[0]][0], reverse=True)[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
