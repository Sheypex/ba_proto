{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    NamedTuple,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Any,\n",
    "    Dict,\n",
    "    Union,\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Sequence,\n",
    ")\n",
    "\n",
    "import rich.panel\n",
    "import sklearn.base\n",
    "from alive_progress import alive_bar\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from log_symbols import LogSymbols\n",
    "\n",
    "import overrides as overrides\n",
    "import pandas as pds\n",
    "import tabulate as tabulate\n",
    "from collections import namedtuple\n",
    "from sklearn import linear_model, metrics, preprocessing, model_selection, svm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from halo import Halo\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn import neural_network, tree\n",
    "from sklearn.model_selection import (\n",
    "    HalvingGridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingRandomSearchCV,\n",
    ")\n",
    "import scipy.stats as scistats\n",
    "\n",
    "import rich.progress\n",
    "import commons\n",
    "from data_types import PickleOut\n",
    "from rich.traceback import install as niceTracebacks\n",
    "from rich.table import Table as rTable\n",
    "\n",
    "from db_actions import db_actions\n",
    "import numpy as np\n",
    "\n",
    "from linRegPred import getSplits, getTransformers\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import r2_score\n",
    "import textdistance as TD\n",
    "from multiprocessing import Pool\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    dF = pds.read_sql('SELECT * FROM \"runtimeScorePredBase1000\"', conn)\n",
    "# print(dF)\n",
    "all_x_cols = [\n",
    "    \"build-linux-kernel1\",\n",
    "    \"fio2\",\n",
    "    \"fio3\",\n",
    "    \"fio4\",\n",
    "    \"fio5\",\n",
    "    \"fio6\",\n",
    "    \"fio7\",\n",
    "    \"fio8\",\n",
    "    \"fio9\",\n",
    "    \"iperf10\",\n",
    "    \"iperf11\",\n",
    "    \"iperf12\",\n",
    "    \"iperf13\",\n",
    "    \"john-the-ripper14\",\n",
    "    \"john-the-ripper15\",\n",
    "    \"ramspeed16\",\n",
    "    \"ramspeed17\",\n",
    "    \"ramspeed18\",\n",
    "    \"ramspeed19\",\n",
    "    \"ramspeed20\",\n",
    "    \"ramspeed21\",\n",
    "    \"ramspeed22\",\n",
    "    \"ramspeed23\",\n",
    "    \"ramspeed24\",\n",
    "    \"ramspeed25\",\n",
    "    \"stream26\",\n",
    "    \"stream27\",\n",
    "    \"stream28\",\n",
    "    \"stream29\",\n",
    "    \"pCpu\",\n",
    "    \"cpus\",\n",
    "    \"rss\",\n",
    "    \"vmem\",\n",
    "    \"rchar\",\n",
    "    \"wchar\",\n",
    "    \"syscr\",\n",
    "    \"syscw\",\n",
    "]\n",
    "filtered_x_cols = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21',\n",
    "                   'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr',\n",
    "                   'syscw']\n",
    "x_cols = all_x_cols\n",
    "y_cols = \"realtime\"\n",
    "\n",
    "X: pds.DataFrame = dF[x_cols]\n",
    "y: pds.DataFrame = dF[y_cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_yaml import yaml_load\n",
    "\n",
    "with open(\"nodeConfigIdLookup.yaml\", \"r\") as f:\n",
    "    t = yaml_load(f)\n",
    "    nodeIDLUT = {v: k for k, v in t.items()}\n",
    "dF[\"nodeName\"] = dF[\"nodeConfig\"].transform(lambda x: nodeIDLUT[x])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "awsGroupLUT = {\n",
    "    \"general\": [\"M7g\", \"Mac\", \"M6g\", \"M6i\", \"M6in\", \"M6a\", \"M5\", \"M5n\", \"M5zn\", \"M5a\", \"M4\", \"A1\", \"T4g\", \"T3\",\n",
    "                \"T3a\",\n",
    "                \"T2\"],\n",
    "    \"compute\": [\"C7g\", \"C7gn\", \"C6i\", \"C6in\", \"C6a\", \"C6g\", \"C6gn\", \"C5\", \"C5n\", \"C5a\", \"C4\"],\n",
    "    \"memory\": [\"R7g\", \"R7iz\", \"R6g\", \"R6i\", \"R6in\", \"R6a\", \"R5\", \"R5n\", \"R5b\", \"R5a\", \"R4\", \"X2gd\", \"X2idn\",\n",
    "               \"X2iedn\",\n",
    "               \"X2iezn\", \"X1\", \"X1e\", \"z1d\"],\n",
    "    \"accelerated\": [\"P4\", \"P3\", \"P2\", \"DL1\", \"Trn1\", \"Inf2\", \"Inf1\", \"G5\", \"G5g\", \"G4dn\", \"G4ad\", \"G3\", \"F1\",\n",
    "                    \"VT1\"],\n",
    "    \"storage\": [\"Im4gn\", \"Is4gen\", \"I4i\", \"I3\", \"I3en\", \"D2\", \"D3\", \"D3en\", \"H1\"],\n",
    "    \"HPC\": [\"Hpc6id\", \"Hpc6a\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "awsInstanceGroupLUT = {i.lower(): k for k, v in awsGroupLUT.items() for i in v}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dF[\"nodeGroup\"] = dF[\"nodeName\"].transform(lambda x: awsInstanceGroupLUT[x.split(\".\")[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "usedAwsGroupLUT = {\n",
    "    k: list(pds.unique(dF.query(\"nodeGroup==@k\").nodeName.values)) for k in awsGroupLUT.keys()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nodesPerGroup = {\n",
    "    k: len(v) for k, v in usedAwsGroupLUT.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "if False:\n",
    "    #sns.boxplot(data=dF,y=\"realtime\",x=\"taskName\",hue=\"nodeGroup\")\n",
    "    for wf in dF.groupby(by=\"wfName\"):\n",
    "        wfname, data = wf\n",
    "        print(wfname)\n",
    "        grid = sns.FacetGrid(data, row=\"wfName\", col=\"nodeGroup\", sharex=False, sharey=True, margin_titles=True,\n",
    "                             height=5)\n",
    "        grid.map_dataframe(sns.boxplot, y=\"realtime\", x=\"taskName\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find prototypes for each group"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_ranks_df = pds.DataFrame()\n",
    "for l, d in dF.groupby(by=[\"wfName\", \"taskName\", \"nodeName\"]):\n",
    "    wn, tn, nn = l\n",
    "    true_ranks_df = true_ranks_df.append(\n",
    "        {\"wfName\": wn, \"taskName\": tn, \"nodeName\": nn, \"realtime\": d.realtime.mean(), \"rank\": 0},\n",
    "        ignore_index=True)\n",
    "\n",
    "for l, d in true_ranks_df.groupby(by=[\"wfName\", \"taskName\"]):\n",
    "    wn, tn = l\n",
    "    ranks = rankdata(d.realtime.values, method=\"min\")\n",
    "    d[\"rank\"] = ranks\n",
    "    true_ranks_df.update(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    scores_df = pds.read_sql('SELECT * FROM \"nodeBenchmarkTransposedScores\"', conn)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_df[\"nodeName\"] = scores_df[\"nodeConfig\"].transform(lambda x: nodeIDLUT[x])\n",
    "scores_df[\"nodeGroup\"] = scores_df[\"nodeName\"].transform(lambda x: awsInstanceGroupLUT[x.split(\".\")[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groupOrder = [\"general\", \"compute\", \"memory\", \"storage\"]\n",
    "nodeOrder = list(pds.unique(dF.nodeName))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benchmarkCols = [\n",
    "    \"build-linux-kernel1\",\n",
    "    \"fio2\",\n",
    "    \"fio3\",\n",
    "    \"fio4\",\n",
    "    \"fio5\",\n",
    "    \"fio6\",\n",
    "    \"fio7\",\n",
    "    \"fio8\",\n",
    "    \"fio9\",\n",
    "    \"iperf10\",\n",
    "    \"iperf11\",\n",
    "    \"iperf12\",\n",
    "    \"iperf13\",\n",
    "    \"john-the-ripper14\",\n",
    "    \"john-the-ripper15\",\n",
    "    \"ramspeed16\",\n",
    "    \"ramspeed17\",\n",
    "    \"ramspeed18\",\n",
    "    \"ramspeed19\",\n",
    "    \"ramspeed20\",\n",
    "    \"ramspeed21\",\n",
    "    \"ramspeed22\",\n",
    "    \"ramspeed23\",\n",
    "    \"ramspeed24\",\n",
    "    \"ramspeed25\",\n",
    "    \"stream26\",\n",
    "    \"stream27\",\n",
    "    \"stream28\",\n",
    "    \"stream29\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_group_protos(benchmarkCols=benchmarkCols, scores_dF=scores_df, groupOrder=groupOrder):\n",
    "    scores = dict()\n",
    "    nodeGroups = [scores_dF.query(\"nodeGroup==@gn\").nodeName.values for gn in groupOrder]\n",
    "    nodeGroupBenchmarkAverages = [np.average([scores_dF.query(\"nodeName==@nn\")[benchmarkCols] for nn in ng], axis=0) for\n",
    "                                  ng\n",
    "                                  in nodeGroups]\n",
    "    for c in itertools.product(*nodeGroups):\n",
    "        proto_benchmarks = [scores_dF.query(\"nodeName == @pn\")[benchmarkCols].values[0] for pn in c]\n",
    "        distance_between_protos = 0\n",
    "        for i, pn1 in enumerate(proto_benchmarks[:-1]):\n",
    "            for pn2 in proto_benchmarks[i + 1:]:\n",
    "                distance_between_protos += np.linalg.norm(pn1 - pn2)\n",
    "        distances_from_group_averages = [np.linalg.norm(bs - ngba) for bs, ngba in\n",
    "                                         zip(proto_benchmarks, nodeGroupBenchmarkAverages)]\n",
    "        scores[c] = (distance_between_protos, np.sum(distances_from_group_averages))\n",
    "    factor = sum(x[0] for x in scores.values()) / sum(x[1] for x in scores.values())\n",
    "    scores = {\n",
    "        k: v[0] + factor * v[1] for k, v in scores.items()\n",
    "    }\n",
    "    cs, ds = scores.keys(), scores.values()\n",
    "    return [x[0] for x in sorted(zip(cs, ds), key=lambda x: x[1])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bestGroupPrototypes = (\n",
    "    'm5.xlarge', 'c5.xlarge', 'r5.xlarge', 'i3.2xlarge')  # = sorted(zip(cs, ds), key=lambda x: x[1])[0][0]\n",
    "bestGroupPrototypesLUT = {\n",
    "    awsInstanceGroupLUT[k.split(\".\")[0]]: k for k in bestGroupPrototypes\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(bestGroupPrototypesLUT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Produce Group Rankings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def makeGroupRankings(prototypes, instanceGroupLUT=awsInstanceGroupLUT, base_dF=dF, groupOrder=groupOrder):\n",
    "    try:\n",
    "        prototypesLUT = {\n",
    "            instanceGroupLUT[k.split(\".\")[0]]: k for k in prototypes\n",
    "        }\n",
    "    except:\n",
    "        prototypesLUT = {\n",
    "            instanceGroupLUT[k]: k for k in prototypes\n",
    "        }\n",
    "    groupPerformances = dict()\n",
    "    for g in base_dF.groupby(by=[\"nodeGroup\", \"wfName\", \"taskName\"]):\n",
    "        l, d = g\n",
    "        ng, wfn, tn = l\n",
    "        if (wfn, tn) not in groupPerformances.keys():\n",
    "            groupPerformances[(wfn, tn)] = dict()\n",
    "        groupProto = prototypesLUT[ng]\n",
    "        groupPerformances[(wfn, tn)][ng] = d.query(\"nodeName == @groupProto\").realtime.mean()\n",
    "        #groupPerformances[l] = d.realtime.mean()\n",
    "    groupRankings = {\"wfName\": [], \"taskName\": [], **{o: [] for o in groupOrder}}\n",
    "    for k, v in groupPerformances.items():\n",
    "        wfn, tn = k\n",
    "        performances = [v[i] for i in groupOrder]\n",
    "        ranks = rankdata(performances, method=\"min\")\n",
    "        groupRankings[\"wfName\"].append(wfn)\n",
    "        groupRankings[\"taskName\"].append(tn)\n",
    "        for o, r in zip(groupOrder, ranks):\n",
    "            groupRankings[o].append(r)\n",
    "    return pds.DataFrame(groupRankings)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Produce intragroup node rankings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def makeNodeRankingsInGroups(groupRankings, base_dF=dF, groupOrder=groupOrder, nodesPerGroup=nodesPerGroup):\n",
    "    tmp = pds.DataFrame(\n",
    "        columns=[\"group\", \"nodeName\", \"wfName\", \"taskName\", \"realtime\", \"groupRank\", \"intraGroupRank\", \"globalRank\",\n",
    "                 \"trueRank\"])\n",
    "    tmp2 = {\"group\": [], \"nodeName\": [], \"wfName\": [], \"taskName\": [], \"realtime\": []}\n",
    "    for g in base_dF.groupby(by=[\"nodeGroup\", \"wfName\", \"taskName\", \"nodeName\"]):\n",
    "        l, d = g\n",
    "        ng, wfn, tn, nn = l\n",
    "        tmp2[\"group\"].append(ng)\n",
    "        tmp2[\"nodeName\"].append(nn)\n",
    "        tmp2[\"wfName\"].append(wfn)\n",
    "        tmp2[\"taskName\"].append(tn)\n",
    "        tmp2[\"realtime\"].append(d.realtime.mean())\n",
    "    tmp = tmp.append(pds.DataFrame(tmp2), ignore_index=True)\n",
    "    del tmp2\n",
    "\n",
    "    for l, d in tmp.groupby([\"group\", \"wfName\", \"taskName\"]):\n",
    "        gr, wfn, tn = l\n",
    "        ra = list(rankdata(d.realtime, method=\"min\"))\n",
    "        cache = groupRankings.query(\"wfName==@wfn and taskName==@tn\")\n",
    "        ar = 0\n",
    "        grr = cache[gr].values[0]\n",
    "        for k, v in sorted(list(zip(groupOrder, (cache[k].values[0] for k in groupOrder))), key=lambda x: x[1]):\n",
    "            if v >= grr:\n",
    "                break\n",
    "            ar += nodesPerGroup[k]\n",
    "        # d[\"intraGroupRank\"] = ra\n",
    "        # d[\"groupRank\"] = [grr] * len(ra)\n",
    "        # d[\"globalRank\"] = np.array([ar] * len(ra)) + np.array(ra)\n",
    "        tmp.update(pds.DataFrame({\"intraGroupRank\": ra, \"groupRank\": [grr] * len(ra),\n",
    "                                  \"globalRank\": np.array([ar] * len(ra)) + np.array(ra)}, index=d.index))\n",
    "\n",
    "    for l, d in tmp.groupby([\"wfName\", \"taskName\"]):\n",
    "        tr = list(rankdata(d.realtime, method=\"min\"))\n",
    "        #d[\"trueRank\"] = tr\n",
    "        tmp.update(pds.DataFrame({\"trueRank\": tr}, index=d.index))\n",
    "\n",
    "    return tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp3 = makeNodeRankingsInGroups(makeGroupRankings(bestGroupPrototypes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export = pds.DataFrame(\n",
    "    {\"wfName\": tmp3.wfName, \"taskName\": tmp3.taskName, \"nodeName\": tmp3.nodeName, \"rank\": tmp3.globalRank})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export.to_csv(\"no_ML_ranks.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scoreRankings(ranking_df):\n",
    "    scores = []\n",
    "    for l, d in ranking_df.groupby(by=[\"wfName\", \"taskName\"]):\n",
    "        scores.append(commons.rankingScore(d.globalRank.values, d.trueRank.values))\n",
    "    return np.average(scores), np.std(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(scoreRankings(tmp3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bruteforce test all prototype selections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def do_one(x):\n",
    "    return x, scoreRankings(makeNodeRankingsInGroups(makeGroupRankings(x)))\n",
    "\n",
    "\n",
    "nodeGroups = [scores_dF.query(\"nodeGroup==@gn\").nodeName.values for gn in groupOrder]\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = pool.map(do_one, itertools.product(*nodeGroups))\n",
    "    prototypeSelectionScores = {c: r for c, r in results}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sorted(zip(prototypeSelectionScores.keys(), prototypeSelectionScores.values()),\n",
    "             key=lambda x: prototypeSelectionScores[x[0]][0], reverse=True)[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New Instance Type Clusterings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def make_clustered_ranking(instanceGroupLUT=awsInstanceGroupLUT):\n",
    "    clustered_dF = dF.copy()\n",
    "    clustered_dF[\"nodeGroup\"] = clustered_dF[\"nodeName\"].transform(lambda x: instanceGroupLUT[x])\n",
    "    clustered_groupOrder = pds.unique(clustered_dF.nodeGroup)\n",
    "    clustered_scores_df = scores_df.copy()\n",
    "    clustered_scores_df[\"nodeGroup\"] = clustered_scores_df[\"nodeName\"].transform(lambda x: instanceGroupLUT[x])\n",
    "    bestClusteredGroupPrototypes = find_group_protos(scores_dF=clustered_scores_df, groupOrder=clustered_groupOrder)[0]\n",
    "    return makeNodeRankingsInGroups(\n",
    "        makeGroupRankings(prototypes=bestClusteredGroupPrototypes, instanceGroupLUT=instanceGroupLUT,\n",
    "                          base_dF=clustered_dF, groupOrder=clustered_groupOrder),\n",
    "        base_dF=clustered_dF,\n",
    "        groupOrder=clustered_groupOrder,\n",
    "        nodesPerGroup={l: len(d.unique()) for l, d in clustered_dF.groupby(\"nodeGroup\").nodeName})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def score_clustering(instanceGroupLUT=awsInstanceGroupLUT):\n",
    "    return scoreRankings(make_clustered_ranking(instanceGroupLUT=instanceGroupLUT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7407233769165323, 0.06563691837236124)\n"
     ]
    }
   ],
   "source": [
    "instanceGroupLUT = {nn: c for nn, c in zip(scores_df.nodeName.values,\n",
    "                                           AffinityPropagation(random_state=None).fit_predict(\n",
    "                                               scores_df[benchmarkCols]))}\n",
    "print(score_clustering(instanceGroupLUT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (0.7702939695438523, 0.043496625716111896)\n",
      "3 (0.8059071729957805, 0.04908270000854898)\n",
      "4 (0.8293656995016583, 0.04422357750589898)\n",
      "5 (0.7662308346790295, 0.05671507707957268)\n",
      "6 (0.7812158149710893, 0.05999482445909217)\n",
      "7 (0.7688006806619091, 0.0662614861873288)\n",
      "8 (0.7654668264138493, 0.06002503000106251)\n",
      "9 (0.8025559549235124, 0.05052909242978613)\n",
      "10 (0.8025038634508864, 0.05019454221858715)\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2, 11):\n",
    "    print(n_clusters, score_clustering({nn: c for nn, c in zip(scores_df.nodeName.values,\n",
    "                                                               KMeans(n_clusters).fit_predict(\n",
    "                                                                   scores_df[benchmarkCols]))}\n",
    "                                       ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8293656995016583, 0.04422357750589898)\n"
     ]
    }
   ],
   "source": [
    "tmp3 = make_clustered_ranking({nn: c for nn, c in zip(scores_df.nodeName.values,\n",
    "                                                               KMeans(n_clusters=4).fit_predict(\n",
    "                                                                   scores_df[benchmarkCols]))}\n",
    "                                       )\n",
    "print(scoreRankings(tmp3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "export = pds.DataFrame(\n",
    "    {\"wfName\": tmp3.wfName, \"taskName\": tmp3.taskName, \"nodeName\": tmp3.nodeName, \"rank\": tmp3.globalRank})\n",
    "export.to_csv(\"no_ML_ranks.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
