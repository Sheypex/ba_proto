{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    NamedTuple,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Any,\n",
    "    Dict,\n",
    "    Union,\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Sequence,\n",
    ")\n",
    "\n",
    "import rich.panel\n",
    "import sklearn.base\n",
    "from alive_progress import alive_bar\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from log_symbols import LogSymbols\n",
    "\n",
    "import overrides as overrides\n",
    "import pandas as pds\n",
    "import tabulate as tabulate\n",
    "from collections import namedtuple\n",
    "from sklearn import linear_model, metrics, preprocessing, model_selection, svm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from halo import Halo\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn import neural_network, tree\n",
    "from sklearn.model_selection import (\n",
    "    HalvingGridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingRandomSearchCV,\n",
    ")\n",
    "import scipy.stats as scistats\n",
    "\n",
    "import rich.progress\n",
    "import commons\n",
    "from data_types import PickleOut\n",
    "from rich.traceback import install as niceTracebacks\n",
    "from rich.table import Table as rTable\n",
    "\n",
    "from db_actions import db_actions\n",
    "import numpy as np\n",
    "\n",
    "from linRegPred import getSplits, getTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    dF = pds.read_sql('SELECT * FROM \"runtimeScorePredBase1000\"', conn)\n",
    "# print(dF)\n",
    "all_x_cols_test = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\",\n",
    "        \"pCpu\",\n",
    "        \"cpus\",\n",
    "        \"rss\",\n",
    "        \"vmem\",\n",
    "        \"rchar\",\n",
    "        \"wchar\",\n",
    "        \"syscr\",\n",
    "        \"syscw\",\n",
    "]\n",
    "filtered_x_cols_test = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21',\n",
    "                        'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr',\n",
    "                        'syscw']\n",
    "x_cols_test = filtered_x_cols_test\n",
    "y_cols_test = \"realtime\"\n",
    "\n",
    "X_test_test: pds.DataFrame = dF[x_cols_test]\n",
    "y: pds.DataFrame = dF[y_cols_test]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deprecated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv\")\n",
    "t.add_column(\"unknown\")\n",
    "t.add_column(\"cv score\")\n",
    "t.add_column(\"unknown score\")\n",
    "for split in getSplits(dF, 1, x_cols_test, y_cols_test, cvSize=1, unknownSize=1):\n",
    "    X_train, y_train, X_test, y_test, X_unknown, y_unknown, X_trans, ukwfs, cvwfs = split\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    # print(cvwfs, ukwfs, model.score(X_test, y_test), model.score(X_unknown, y_unknown))\n",
    "    t.add_row(cvwfs[0], ukwfs[0], str(model.score(X_test, y_test)), str(model.score(X_unknown, y_unknown)))\n",
    "rich.print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X_test_test, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X_test_test)))\n",
    "res2 = list()\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, test_size=0.2)\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    res2.append(model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rich.print(np.average(res2), np.std(res2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Current"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "taskNames = pds.unique(dF.taskName)\n",
    "\n",
    "\n",
    "def pickCVTasks():\n",
    "    cvTasks = list(taskNames)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"taskName in @cvTasks\")) > .3 * totalData:\n",
    "        cvTasks = list()\n",
    "        remainingTasks = list(taskNames)\n",
    "        while len(dF.query(\"taskName in @cvTasks\")) < .2 * totalData:\n",
    "            pick = np.random.choice(remainingTasks)\n",
    "            remainingTasks.remove(pick)\n",
    "            cvTasks.append(pick)\n",
    "    return cvTasks\n",
    "\n",
    "\n",
    "nodeIds = pds.unique(dF.nodeConfig)\n",
    "\n",
    "\n",
    "def pickCVNodes():\n",
    "    cvNodes = list(nodeIds)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"nodeConfig in @cvNodes\")) > .85 * totalData:\n",
    "        cvNodes = list()\n",
    "        remainingNodes = list(nodeIds)\n",
    "        while len(dF.query(\"nodeConfig in @cvNodes\")) < .8 * totalData:\n",
    "            pick = np.random.choice(remainingNodes)\n",
    "            remainingNodes.remove(pick)\n",
    "            cvNodes.append(pick)\n",
    "    return cvNodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def listProd(l):\n",
    "    return reduce(lambda a, x: a * x, l, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X_test_test, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X_test_test)))\n",
    "res2 = list()\n",
    "done = set()\n",
    "for i in range(100):\n",
    "    cvNodes = pickCVNodes()\n",
    "    #while listProd([i - 164 for i in cvNodes]) in done:\n",
    "    #    cvNodes = pickCVNodes()\n",
    "    #done.add(listProd([i - 164 for i in cvNodes]))\n",
    "    train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "    X_train = train[x_cols_test]\n",
    "    X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "    y_train = train[y_cols_test]\n",
    "    test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "    X_test = test[x_cols_test]\n",
    "    X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "    y_test = test[y_cols_test]\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    #model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    res2.append((cvNodes, model.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv tasks\")\n",
    "t.add_column(\"score\")\n",
    "for r in res2[:5]:\n",
    "    cv, s = r\n",
    "    print(cv, s)\n",
    "    #t.add_row(\", \".join(list(cv)), str(s))\n",
    "print(\"average:\", np.average([s for cv, s in res2]), \"std:\", np.std([s for cv, s in res2]))\n",
    "#rich.print(t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = dict()\n",
    "seen = dict()\n",
    "for r in res2:\n",
    "    cv, s = r\n",
    "    for c in cv:\n",
    "        if c not in tmp.keys():\n",
    "            tmp[c] = 0\n",
    "            seen[c] = 0\n",
    "        tmp[c] = tmp[c] + s / len(cv)\n",
    "        seen[c] = seen[c] + 1\n",
    "for k in tmp.keys():\n",
    "    tmp[k] = tmp[k] / seen[k]\n",
    "t1 = tmp.keys()\n",
    "t2 = tmp.values()\n",
    "t = list(zip(t1, t2))\n",
    "print(sorted(t, key=lambda x: x[1]))\n",
    "print(np.average(list(t2)), np.std(list(t2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test n cv nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "nodeIds = pds.unique(dF.nodeConfig)\n",
    "\n",
    "\n",
    "def pickNCVNodes(n):\n",
    "    return np.random.choice(nodeIds, size=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X_test_test, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X_test_test)))\n",
    "res2 = list()\n",
    "done = set()\n",
    "for n in range(1, len(nodeIds)):\n",
    "    for i in range(min(100, len(nodeIds) ** n)):\n",
    "        cvNodes = pickNCVNodes(n)\n",
    "        #while listProd([i - 164 for i in cvNodes]) in done:\n",
    "        #    cvNodes = pickCVNodes()\n",
    "        #done.add(listProd([i - 164 for i in cvNodes]))\n",
    "        train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "        X_train = train[x_cols_test]\n",
    "        X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "        y_train = train[y_cols_test]\n",
    "        test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "        X_test = test[x_cols_test]\n",
    "        X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "        y_test = test[y_cols_test]\n",
    "        model = tree.DecisionTreeRegressor()\n",
    "        #model = linear_model.LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        res2.append((n, cvNodes, model.score(X_test, y_test)))\n",
    "    print(n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp2 = dict()\n",
    "for r in res2:\n",
    "    n, cv, s = r\n",
    "    if n not in tmp2.keys():\n",
    "        tmp2[n] = list()\n",
    "    tmp2[n].append(s)\n",
    "tmp3 = list()\n",
    "for k, v in tmp2.items():\n",
    "    print(k, np.average(v), np.std(v))\n",
    "    tmp3.append(np.average(v))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "p = sns.lineplot(x=range(1, len(nodeIds)), y=tmp3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test rank accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = getTransformers(X_test_test, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "cvNodes = pickCVNodes()\n",
    "train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "X_train = train[x_cols_test]\n",
    "X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "y_train = train[y_cols_test]\n",
    "test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "X_test = test[x_cols_test]\n",
    "X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "y_test = test[y_cols_test]\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;36m0.8753072180422782\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8753072180422782</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;36m0.8963717890947415\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8963717890947415</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.score(scale2.transform(poly.transform(scale1.transform(X_test_test))), y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "ranks = dF[\"rank\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;35marray\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m \u001B[1;36m3646\u001B[0m.,  \u001B[1;36m3648\u001B[0m.,  \u001B[1;36m9715\u001B[0m., \u001B[33m...\u001B[0m,  \u001B[1;36m6000\u001B[0m.,  \u001B[1;36m7589\u001B[0m., \u001B[1;36m33096\u001B[0m.\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3646</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3648</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9715</span>., <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6000</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7589</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33096</span>.<span style=\"font-weight: bold\">])</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.predict(scale2.transform(poly.transform(scale1.transform(X_test_test))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tasks = pds.unique(dF[\"taskName\"])\n",
    "wfs = pds.unique(dF[\"wfName\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    test_df = pds.read_sql('SELECT * FROM \"averageRuntimeScorePredBase1000\"', conn)\n",
    "# print(test_df)\n",
    "all_x_cols_test = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\",\n",
    "        \"pCpu\",\n",
    "        \"cpus\",\n",
    "        \"rss\",\n",
    "        \"vmem\",\n",
    "        \"rchar\",\n",
    "        \"wchar\",\n",
    "        \"syscr\",\n",
    "        \"syscw\",\n",
    "]\n",
    "filtered_x_cols_test = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21',\n",
    "                        'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr',\n",
    "                        'syscw']\n",
    "x_cols_test = filtered_x_cols_test\n",
    "y_cols_test = \"realtime\"\n",
    "\n",
    "X_test_test: pds.DataFrame = test_df[x_cols_test]\n",
    "y_test_test: pds.DataFrame = test_df[y_cols_test]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "res3 = pds.DataFrame(columns=[\"nodeid\", \"task\", \"wf\", \"realtime\", \"pred\", \"predrank\", \"rank\"])\n",
    "for t, w in test_df[[\"taskName\", \"wfName\"]].values:\n",
    "    dummy1 = [t]\n",
    "    dummy2 = [w]\n",
    "    q = test_df.query(\"taskName in @dummy1 and wfName in @dummy2\")\n",
    "    p = model.predict(scale2.transform(poly.transform(scale1.transform(q[x_cols_test]))))\n",
    "    predranks = rankdata(p, method=\"min\")\n",
    "    for i, row in enumerate(q.values):\n",
    "        # print(row)\n",
    "        nid, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, taskName, wfName, _, _, _, _, _, _, _, _, realtime, rank = tuple(\n",
    "                row)\n",
    "        res3 = res3.append(\n",
    "                {\"nodeid\": nid, \"task\": taskName, \"wf\": wfName, \"realtime\": realtime, \"rank\": rank, \"pred\": p[i],\n",
    "                 \"predrank\": predranks[i]},\n",
    "                ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nodeid</th>\n      <th>task</th>\n      <th>wf</th>\n      <th>realtime</th>\n      <th>pred</th>\n      <th>predrank</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15730.266667</td>\n      <td>18014.0</td>\n      <td>18</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>166</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15871.033333</td>\n      <td>12049.0</td>\n      <td>1</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>167</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15412.533333</td>\n      <td>12049.0</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>168</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>19916.533333</td>\n      <td>19683.0</td>\n      <td>21</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>20376.266667</td>\n      <td>23964.0</td>\n      <td>25</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57586</th>\n      <td>189</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>6785.133333</td>\n      <td>6277.0</td>\n      <td>26</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>57587</th>\n      <td>190</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>6510.266667</td>\n      <td>5769.0</td>\n      <td>15</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>57588</th>\n      <td>191</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3831.833333</td>\n      <td>5921.0</td>\n      <td>21</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>57589</th>\n      <td>192</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3818.000000</td>\n      <td>3532.0</td>\n      <td>6</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>57590</th>\n      <td>193</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3772.750000</td>\n      <td>3532.0</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>57591 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.81200187529302\n"
     ]
    }
   ],
   "source": [
    "print(np.average((res3[\"rank\"] - res3[\"predrank\"]) ** 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104354513.6746089\n"
     ]
    }
   ],
   "source": [
    "print(np.average((res3[\"realtime\"] - res3[\"pred\"]) ** 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
