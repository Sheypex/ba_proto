{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    NamedTuple,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Any,\n",
    "    Dict,\n",
    "    Union,\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Sequence,\n",
    ")\n",
    "\n",
    "import rich.panel\n",
    "import sklearn.base\n",
    "from alive_progress import alive_bar\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from log_symbols import LogSymbols\n",
    "\n",
    "import overrides as overrides\n",
    "import pandas as pds\n",
    "import tabulate as tabulate\n",
    "from collections import namedtuple\n",
    "from sklearn import linear_model, metrics, preprocessing, model_selection, svm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from halo import Halo\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn import neural_network, tree\n",
    "from sklearn.model_selection import (\n",
    "    HalvingGridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingRandomSearchCV,\n",
    ")\n",
    "import scipy.stats as scistats\n",
    "\n",
    "import rich.progress\n",
    "import commons\n",
    "from data_types import PickleOut\n",
    "from rich.traceback import install as niceTracebacks\n",
    "from rich.table import Table as rTable\n",
    "\n",
    "from db_actions import db_actions\n",
    "import numpy as np\n",
    "\n",
    "from linRegPred import getSplits, getTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    dF = pds.read_sql('SELECT * FROM \"runtimeScorePredBase1000\"', conn)\n",
    "# print(dF)\n",
    "all_x_cols = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\",\n",
    "        \"pCpu\",\n",
    "        \"cpus\",\n",
    "        \"rss\",\n",
    "        \"vmem\",\n",
    "        \"rchar\",\n",
    "        \"wchar\",\n",
    "        \"syscr\",\n",
    "        \"syscw\",\n",
    "]\n",
    "filtered_x_cols = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21', 'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr', 'syscw']\n",
    "x_cols = filtered_x_cols\n",
    "y_cols = \"realtime\"\n",
    "\n",
    "X: pds.DataFrame = dF[x_cols]\n",
    "y: pds.DataFrame = dF[y_cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv\")\n",
    "t.add_column(\"unknown\")\n",
    "t.add_column(\"cv score\")\n",
    "t.add_column(\"unknown score\")\n",
    "for split in getSplits(dF, 1, x_cols, y_cols, cvSize=1, unknownSize=1):\n",
    "    X_train, y_train, X_test, y_test, X_unknown, y_unknown, X_trans, ukwfs, cvwfs = split\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    # print(cvwfs, ukwfs, model.score(X_test, y_test), model.score(X_unknown, y_unknown))\n",
    "    t.add_row(cvwfs[0], ukwfs[0], str(model.score(X_test, y_test)), str(model.score(X_unknown, y_unknown)))\n",
    "rich.print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X)))\n",
    "res = list()\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, test_size=0.2)\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    res.append(model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rich.print(np.average(res), np.std(res))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "taskNames = pds.unique(dF.taskName)\n",
    "\n",
    "\n",
    "def pickCVTasks():\n",
    "    cvTasks = list(taskNames)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"taskName in @cvTasks\")) > .3 * totalData:\n",
    "        cvTasks = list()\n",
    "        remainingTasks = list(taskNames)\n",
    "        while len(dF.query(\"taskName in @cvTasks\")) < .2 * totalData:\n",
    "            pick = np.random.choice(remainingTasks)\n",
    "            remainingTasks.remove(pick)\n",
    "            cvTasks.append(pick)\n",
    "    return cvTasks\n",
    "\n",
    "\n",
    "nodeIds = pds.unique(dF.nodeConfig)\n",
    "\n",
    "\n",
    "def pickCVNodes():\n",
    "    cvNodes = list(nodeIds)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"nodeConfig in @cvNodes\")) > .85 * totalData:\n",
    "        cvNodes = list()\n",
    "        remainingNodes = list(nodeIds)\n",
    "        while len(dF.query(\"nodeConfig in @cvNodes\")) < .8 * totalData:\n",
    "            pick = np.random.choice(remainingNodes)\n",
    "            remainingNodes.remove(pick)\n",
    "            cvNodes.append(pick)\n",
    "    return cvNodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def listProd(l):\n",
    "    return reduce(lambda a, x: a * x, l, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X)))\n",
    "res = list()\n",
    "done = set()\n",
    "for i in range(100):\n",
    "    cvNodes = pickCVNodes()\n",
    "    #while listProd([i - 164 for i in cvNodes]) in done:\n",
    "    #    cvNodes = pickCVNodes()\n",
    "    #done.add(listProd([i - 164 for i in cvNodes]))\n",
    "    train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "    X_train = train[x_cols]\n",
    "    X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "    y_train = train[y_cols]\n",
    "    test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "    X_test = test[x_cols]\n",
    "    X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "    y_test = test[y_cols]\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    #model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    res.append((cvNodes, model.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167, 178, 184, 189, 192, 182, 169, 170, 179, 187, 191, 166, 181, 165, 168, 171, 172, 175, 188, 180, 193, 186] 0.9118759636342564\n",
      "[187, 183, 182, 165, 175, 172, 184, 180, 173, 188, 192, 179, 186, 178, 191, 167, 190, 166, 169, 176, 181, 185] 0.8772595314415776\n",
      "[172, 186, 175, 190, 192, 188, 181, 180, 187, 171, 169, 179, 183, 191, 173, 184, 166, 167, 182, 178, 165, 170] 0.8955091650613322\n",
      "[185, 181, 166, 180, 190, 179, 168, 192, 175, 167, 173, 193, 170, 178, 187, 186, 171, 188, 172, 191, 169, 184] 0.9209683087890367\n",
      "[175, 166, 172, 187, 190, 191, 176, 184, 181, 183, 193, 169, 192, 173, 178, 168, 188, 186, 179, 171, 167, 185] 0.9214343784076142\n",
      "average: 0.8845131692779443 std: 0.04664187183458884\n"
     ]
    }
   ],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv tasks\")\n",
    "t.add_column(\"score\")\n",
    "for r in res[:5]:\n",
    "    cv, s = r\n",
    "    print(cv, s)\n",
    "    #t.add_row(\", \".join(list(cv)), str(s))\n",
    "print(\"average:\", np.average([s for cv, s in res]), \"std:\", np.std([s for cv, s in res]))\n",
    "#rich.print(t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(170, 0.04028053635860174), (183, 0.04029801920233973), (180, 0.040298742156475206), (168, 0.040319782367888926), (192, 0.04033043355258681), (181, 0.04035885691424642), (186, 0.040362572584791256), (185, 0.04036583177935518), (182, 0.040369344857983505), (193, 0.04037284791298116), (165, 0.04037545257172535), (187, 0.04039085935410132), (179, 0.04039099429330804), (172, 0.04039603013279658), (166, 0.0403988508756666), (167, 0.04039903367842179), (173, 0.04040689074400878), (190, 0.04041256492346465), (175, 0.04041589013152856), (169, 0.04042175402727249), (178, 0.04042445914477014), (176, 0.040449038370745975), (191, 0.04045089257760816), (188, 0.04047747528241734), (184, 0.04058861225684818), (189, 0.040601681521309364), (171, 0.04066593687852045)]\n",
      "0.04040827349821347 8.831200077538215e-05\n"
     ]
    }
   ],
   "source": [
    "tmp = dict()\n",
    "seen = dict()\n",
    "for r in res:\n",
    "    cv, s = r\n",
    "    for c in cv:\n",
    "        if c not in tmp.keys():\n",
    "            tmp[c] = 0\n",
    "            seen[c] = 0\n",
    "        tmp[c] = tmp[c] + s / len(cv)\n",
    "        seen[c] = seen[c] + 1\n",
    "for k in tmp.keys():\n",
    "    tmp[k] = tmp[k] / seen[k]\n",
    "t1 = tmp.keys()\n",
    "t2 = tmp.values()\n",
    "t = list(zip(t1, t2))\n",
    "print(sorted(t, key=lambda x: x[1]))\n",
    "print(np.average(list(t2)), np.std(list(t2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
