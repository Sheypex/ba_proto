{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    NamedTuple,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Any,\n",
    "    Dict,\n",
    "    Union,\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Sequence,\n",
    ")\n",
    "\n",
    "import rich.panel\n",
    "import sklearn.base\n",
    "from alive_progress import alive_bar\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from log_symbols import LogSymbols\n",
    "\n",
    "import overrides as overrides\n",
    "import pandas as pds\n",
    "import tabulate as tabulate\n",
    "from collections import namedtuple\n",
    "from sklearn import linear_model, metrics, preprocessing, model_selection, svm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from halo import Halo\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn import neural_network, tree\n",
    "from sklearn.model_selection import (\n",
    "    HalvingGridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingRandomSearchCV,\n",
    ")\n",
    "import scipy.stats as scistats\n",
    "\n",
    "import rich.progress\n",
    "import commons\n",
    "from data_types import PickleOut\n",
    "from rich.traceback import install as niceTracebacks\n",
    "from rich.table import Table as rTable\n",
    "\n",
    "from db_actions import db_actions\n",
    "import numpy as np\n",
    "\n",
    "from linRegPred import getSplits, getTransformers\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    dF = pds.read_sql('SELECT * FROM \"runtimeScorePredBase1000\"', conn)\n",
    "# print(dF)\n",
    "all_x_cols = [\n",
    "        \"build-linux-kernel1\",\n",
    "        \"fio2\",\n",
    "        \"fio3\",\n",
    "        \"fio4\",\n",
    "        \"fio5\",\n",
    "        \"fio6\",\n",
    "        \"fio7\",\n",
    "        \"fio8\",\n",
    "        \"fio9\",\n",
    "        \"iperf10\",\n",
    "        \"iperf11\",\n",
    "        \"iperf12\",\n",
    "        \"iperf13\",\n",
    "        \"john-the-ripper14\",\n",
    "        \"john-the-ripper15\",\n",
    "        \"ramspeed16\",\n",
    "        \"ramspeed17\",\n",
    "        \"ramspeed18\",\n",
    "        \"ramspeed19\",\n",
    "        \"ramspeed20\",\n",
    "        \"ramspeed21\",\n",
    "        \"ramspeed22\",\n",
    "        \"ramspeed23\",\n",
    "        \"ramspeed24\",\n",
    "        \"ramspeed25\",\n",
    "        \"stream26\",\n",
    "        \"stream27\",\n",
    "        \"stream28\",\n",
    "        \"stream29\",\n",
    "        \"pCpu\",\n",
    "        \"cpus\",\n",
    "        \"rss\",\n",
    "        \"vmem\",\n",
    "        \"rchar\",\n",
    "        \"wchar\",\n",
    "        \"syscr\",\n",
    "        \"syscw\",\n",
    "]\n",
    "filtered_x_cols = ['john-the-ripper15', 'ramspeed17', 'ramspeed18', 'ramspeed19', 'ramspeed20', 'ramspeed21',\n",
    "                   'ramspeed23', 'ramspeed24', 'ramspeed25', 'pCpu', 'cpus', 'vmem', 'rchar', 'wchar', 'syscr',\n",
    "                   'syscw']\n",
    "x_cols = filtered_x_cols\n",
    "y_cols = \"realtime\"\n",
    "\n",
    "X: pds.DataFrame = dF[x_cols]\n",
    "y: pds.DataFrame = dF[y_cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deprecated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv\")\n",
    "t.add_column(\"unknown\")\n",
    "t.add_column(\"cv score\")\n",
    "t.add_column(\"unknown score\")\n",
    "for split in getSplits(dF, 1, x_cols, y_cols, cvSize=1, unknownSize=1):\n",
    "    X_train, y_train, X_test, y_test, X_unknown, y_unknown, X_trans, ukwfs, cvwfs = split\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    # print(cvwfs, ukwfs, model.score(X_test, y_test), model.score(X_unknown, y_unknown))\n",
    "    t.add_row(cvwfs[0], ukwfs[0], str(model.score(X_test, y_test)), str(model.score(X_unknown, y_unknown)))\n",
    "rich.print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X)))\n",
    "res2 = list()\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, test_size=0.2)\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    res2.append(model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rich.print(np.average(res2), np.std(res2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Current"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "taskNames = pds.unique(dF.taskName)\n",
    "\n",
    "\n",
    "def pickCVTasks():\n",
    "    cvTasks = list(taskNames)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"taskName in @cvTasks\")) > .3 * totalData:\n",
    "        cvTasks = list()\n",
    "        remainingTasks = list(taskNames)\n",
    "        while len(dF.query(\"taskName in @cvTasks\")) < .2 * totalData:\n",
    "            pick = np.random.choice(remainingTasks)\n",
    "            remainingTasks.remove(pick)\n",
    "            cvTasks.append(pick)\n",
    "    return cvTasks\n",
    "\n",
    "\n",
    "nodeIds = pds.unique(dF.nodeConfig)\n",
    "\n",
    "\n",
    "def pickCVNodes(p=0.8):\n",
    "    cvNodes = list(nodeIds)\n",
    "    totalData = len(dF)\n",
    "    while len(dF.query(\"nodeConfig in @cvNodes\")) > (p + 0.05) * totalData:\n",
    "        cvNodes = list()\n",
    "        remainingNodes = list(nodeIds)\n",
    "        while len(dF.query(\"nodeConfig in @cvNodes\")) < p * totalData:\n",
    "            pick = np.random.choice(remainingNodes)\n",
    "            remainingNodes.remove(pick)\n",
    "            cvNodes.append(pick)\n",
    "    return cvNodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def listProd(l):\n",
    "    return reduce(lambda a, x: a * x, l, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X)))\n",
    "res2 = list()\n",
    "done = set()\n",
    "for i in range(100):\n",
    "    cvNodes = pickCVNodes()\n",
    "    #while listProd([i - 164 for i in cvNodes]) in done:\n",
    "    #    cvNodes = pickCVNodes()\n",
    "    #done.add(listProd([i - 164 for i in cvNodes]))\n",
    "    train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "    X_train = train[x_cols]\n",
    "    X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "    y_train = train[y_cols]\n",
    "    test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "    X_test = test[x_cols]\n",
    "    X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "    y_test = test[y_cols]\n",
    "    model = tree.DecisionTreeRegressor()\n",
    "    #model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    res2.append((cvNodes, model.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = rTable(title=\"results\")\n",
    "t.add_column(\"cv tasks\")\n",
    "t.add_column(\"score\")\n",
    "for r in res2[:5]:\n",
    "    cv, s = r\n",
    "    print(cv, s)\n",
    "    #t.add_row(\", \".join(list(cv)), str(s))\n",
    "print(\"average:\", np.average([s for cv, s in res2]), \"std:\", np.std([s for cv, s in res2]))\n",
    "#rich.print(t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = dict()\n",
    "seen = dict()\n",
    "for r in res2:\n",
    "    cv, s = r\n",
    "    for c in cv:\n",
    "        if c not in tmp.keys():\n",
    "            tmp[c] = 0\n",
    "            seen[c] = 0\n",
    "        tmp[c] = tmp[c] + s / len(cv)\n",
    "        seen[c] = seen[c] + 1\n",
    "for k in tmp.keys():\n",
    "    tmp[k] = tmp[k] / seen[k]\n",
    "t1 = tmp.keys()\n",
    "t2 = tmp.values()\n",
    "t = list(zip(t1, t2))\n",
    "print(sorted(t, key=lambda x: x[1]))\n",
    "print(np.average(list(t2)), np.std(list(t2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test n cv nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "nodeIds = pds.unique(dF.nodeConfig)\n",
    "\n",
    "\n",
    "def pickNCVNodes(n):\n",
    "    return np.random.choice(nodeIds, size=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "X_scaled = scale2.transform(poly.transform(scale1.transform(X)))\n",
    "res2 = list()\n",
    "done = set()\n",
    "for n in range(1, len(nodeIds)):\n",
    "    for i in range(min(100, len(nodeIds) ** n)):\n",
    "        cvNodes = pickNCVNodes(n)\n",
    "        #while listProd([i - 164 for i in cvNodes]) in done:\n",
    "        #    cvNodes = pickCVNodes()\n",
    "        #done.add(listProd([i - 164 for i in cvNodes]))\n",
    "        train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "        X_train = train[x_cols]\n",
    "        X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "        y_train = train[y_cols]\n",
    "        test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "        X_test = test[x_cols]\n",
    "        X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "        y_test = test[y_cols]\n",
    "        model = tree.DecisionTreeRegressor()\n",
    "        #model = linear_model.LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        res2.append((n, cvNodes, model.score(X_test, y_test)))\n",
    "    print(n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp2 = dict()\n",
    "for r in res2:\n",
    "    n, cv, s = r\n",
    "    if n not in tmp2.keys():\n",
    "        tmp2[n] = list()\n",
    "    tmp2[n].append(s)\n",
    "tmp3 = list()\n",
    "for k, v in tmp2.items():\n",
    "    print(k, np.average(v), np.std(v))\n",
    "    tmp3.append(np.average(v))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "p = sns.lineplot(x=range(1, len(nodeIds)), y=tmp3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test rank accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = getTransformers(X, 1)\n",
    "scale1, poly, scale2 = X_trans\n",
    "cvNodes = pickCVNodes(.5)\n",
    "train = dF.query(\"nodeConfig not in @cvNodes\")\n",
    "X_train = train[x_cols]\n",
    "X_train = scale2.transform(poly.transform(scale1.transform(X_train)))\n",
    "y_train = train[y_cols]\n",
    "test = dF.query(\"nodeConfig in @cvNodes\")\n",
    "X_test = test[x_cols]\n",
    "X_test = scale2.transform(poly.transform(scale1.transform(X_test)))\n",
    "y_test = test[y_cols]\n",
    "model = tree.DecisionTreeRegressor()\n",
    "#model = neural_network.MLPRegressor(max_iter=1000)\n",
    "#model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;36m0.8120422565459009\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8120422565459009</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;36m0.907500627863959\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.907500627863959</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.score(scale2.transform(poly.transform(scale1.transform(X))), y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "ranks = dF[\"rank\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;35marray\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0m \u001B[1;36m3517\u001B[0m.,  \u001B[1;36m5041\u001B[0m.,  \u001B[1;36m6820\u001B[0m., \u001B[33m...\u001B[0m,  \u001B[1;36m6000\u001B[0m.,  \u001B[1;36m7143\u001B[0m., \u001B[1;36m32821\u001B[0m.\u001B[1m]\u001B[0m\u001B[1m)\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3517</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5041</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6820</span>., <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6000</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7143</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32821</span>.<span style=\"font-weight: bold\">])</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.predict(scale2.transform(poly.transform(scale1.transform(X))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "tasks = pds.unique(dF[\"taskName\"])\n",
    "wfs = pds.unique(dF[\"wfName\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "with db_actions.connect() as conn:\n",
    "    test_df = pds.read_sql('SELECT * FROM \"averageRuntimeScorePredBase1000\"', conn)\n",
    "# print(test_df)\n",
    "X_test_test: pds.DataFrame = test_df[x_cols]\n",
    "y_test_test: pds.DataFrame = test_df[y_cols]\n",
    "\n",
    "X_trans_test = getTransformers(X_test_test, 1)\n",
    "scale1_test, poly_test, scale2_test = X_trans_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.280530446496583\n"
     ]
    }
   ],
   "source": [
    "model.predict(scale2_test.transform(poly_test.transform(scale1_test.transform(X_test_test))))\n",
    "t = model.predict(scale2_test.transform(poly_test.transform(scale1_test.transform(X_test_test))))\n",
    "yo = test_df.assign(predTime = t)\n",
    "yo = yo.sort_values(by=[\"wfName\", \"taskName\", \"nodeConfig\"],ignore_index=True)\n",
    "#print(yo)\n",
    "#print(rankdata(np.array(yo.predTime).reshape((-1,27)), method=\"min\", axis=1).reshape((-1)))\n",
    "yo = yo.assign(predRank=rankdata(np.array(yo.predTime).reshape((-1,27)), method=\"min\", axis=1).reshape((-1)))\n",
    "#print(yo)\n",
    "comp1 = np.array(yo[\"rank\"]).reshape((-1,27))\n",
    "comp2 = np.array(yo.predRank).reshape((-1,27))\n",
    "print(r2_score(comp1, comp2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.05      0.42      0.09        81\n",
      "           2       0.03      0.01      0.02        86\n",
      "           3       0.06      0.06      0.06        89\n",
      "           4       0.05      0.04      0.04        83\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.04      0.01      0.02        75\n",
      "           7       0.02      0.01      0.01        79\n",
      "           8       0.04      0.01      0.02        80\n",
      "           9       0.03      0.03      0.03        74\n",
      "          10       0.02      0.02      0.02        83\n",
      "          11       0.00      0.00      0.00        76\n",
      "          12       0.03      0.03      0.03        78\n",
      "          13       0.07      0.08      0.07        77\n",
      "          14       0.04      0.03      0.03        79\n",
      "          15       0.03      0.02      0.03        84\n",
      "          16       0.06      0.12      0.09        80\n",
      "          17       0.00      0.00      0.00        72\n",
      "          18       0.05      0.06      0.05        70\n",
      "          19       0.06      0.04      0.05        96\n",
      "          20       0.04      0.04      0.04        73\n",
      "          21       0.02      0.01      0.02        79\n",
      "          22       0.06      0.03      0.04        77\n",
      "          23       0.06      0.04      0.05        79\n",
      "          24       0.07      0.06      0.07        77\n",
      "          25       0.11      0.02      0.04        82\n",
      "          26       0.04      0.03      0.03        74\n",
      "          27       0.25      0.03      0.05        74\n",
      "\n",
      "    accuracy                           0.05      2133\n",
      "   macro avg       0.05      0.05      0.04      2133\n",
      "weighted avg       0.05      0.05      0.04      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yo[\"rank\"], yo.predRank))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res3 = pds.DataFrame(\n",
    "        columns=[\"nodeid\", \"task\", \"wf\", \"realtime\", \"pred\", \"predrank\", \"rank\", \"angle\", \"dist\", \"metric\"])\n",
    "res4 = list()\n",
    "res5 = list()\n",
    "for t, w in test_df[[\"taskName\", \"wfName\"]].values:\n",
    "    dummy1 = [t]\n",
    "    dummy2 = [w]\n",
    "    q = test_df.query(\"taskName in @dummy1 and wfName in @dummy2\")\n",
    "    p = model.predict(scale2_test.transform(poly_test.transform(scale1_test.transform(q[x_cols]))))\n",
    "    predranks = rankdata(p, method=\"min\")\n",
    "    qo = np.array(sorted(q[[\"nodeConfig\", \"rank\"]].values, key=lambda x: x[1]))[:, 0]\n",
    "    po = np.array(sorted(zip(q.nodeConfig, predranks), key=lambda x: x[1]))[:, 0]\n",
    "    qo2 = np.array(sorted(q[[\"nodeConfig\", \"rank\"]].values, key=lambda x: x[0]))[:, 1]\n",
    "    po2 = np.array(sorted(zip(q.nodeConfig, predranks), key=lambda x: x[0]))[:, 1]\n",
    "    res4.append(qo2)#q[\"rank\"])\n",
    "    res5.append(po2)#predranks)\n",
    "    insert = pds.DataFrame(\n",
    "            data={\"nodeid\": q.nodeConfig, \"task\": q.taskName, \"wf\": q.wfName, \"realtime\": q.realtime, \"rank\": q[\"rank\"],\n",
    "                  \"pred\": p,\n",
    "                  \"predrank\": predranks, \"angle\": np.arccos((po.T @ qo) / (np.linalg.norm(qo) * np.linalg.norm(po))),\n",
    "                  \"dist\": np.linalg.norm(po - qo),\n",
    "                  \"metric\": np.linalg.norm((qo2 - po2))},\n",
    "            columns=[\"nodeid\", \"task\", \"wf\", \"realtime\", \"pred\", \"predrank\", \"rank\", \"angle\", \"dist\", \"metric\"])\n",
    "    res3 = res3.append(insert, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nodeid</th>\n      <th>task</th>\n      <th>wf</th>\n      <th>realtime</th>\n      <th>pred</th>\n      <th>predrank</th>\n      <th>rank</th>\n      <th>angle</th>\n      <th>dist</th>\n      <th>metric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15730.266667</td>\n      <td>17877.0</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0.057276</td>\n      <td>53.40412</td>\n      <td>33.105891</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>166</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15871.033333</td>\n      <td>14486.0</td>\n      <td>12</td>\n      <td>17</td>\n      <td>0.057276</td>\n      <td>53.40412</td>\n      <td>33.105891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>167</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>15412.533333</td>\n      <td>10263.0</td>\n      <td>4</td>\n      <td>13</td>\n      <td>0.057276</td>\n      <td>53.40412</td>\n      <td>33.105891</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>168</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>19916.533333</td>\n      <td>17877.0</td>\n      <td>16</td>\n      <td>22</td>\n      <td>0.057276</td>\n      <td>53.40412</td>\n      <td>33.105891</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169</td>\n      <td>TRIMGALORE</td>\n      <td>nfcore/chipseq:1.2.2</td>\n      <td>20376.266667</td>\n      <td>19080.0</td>\n      <td>24</td>\n      <td>25</td>\n      <td>0.057276</td>\n      <td>53.40412</td>\n      <td>33.105891</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57586</th>\n      <td>189</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>6785.133333</td>\n      <td>8000.0</td>\n      <td>16</td>\n      <td>27</td>\n      <td>0.060041</td>\n      <td>55.98214</td>\n      <td>47.655010</td>\n    </tr>\n    <tr>\n      <th>57587</th>\n      <td>190</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>6510.266667</td>\n      <td>5381.0</td>\n      <td>10</td>\n      <td>24</td>\n      <td>0.060041</td>\n      <td>55.98214</td>\n      <td>47.655010</td>\n    </tr>\n    <tr>\n      <th>57588</th>\n      <td>191</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3831.833333</td>\n      <td>10415.0</td>\n      <td>26</td>\n      <td>10</td>\n      <td>0.060041</td>\n      <td>55.98214</td>\n      <td>47.655010</td>\n    </tr>\n    <tr>\n      <th>57589</th>\n      <td>192</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3818.000000</td>\n      <td>4273.0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0.060041</td>\n      <td>55.98214</td>\n      <td>47.655010</td>\n    </tr>\n    <tr>\n      <th>57590</th>\n      <td>193</td>\n      <td>ApplyBQSR</td>\n      <td>nfcore/sarek:2.7.1</td>\n      <td>3772.750000</td>\n      <td>4273.0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>0.060041</td>\n      <td>55.98214</td>\n      <td>47.655010</td>\n    </tr>\n  </tbody>\n</table>\n<p>57591 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;36m-10.280530446496574\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-10.280530446496574</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_score(res4, res5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2233.8439963435226\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(res3[\"rank\"] - res3[\"predrank\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914678.00391379\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm((res3[\"realtime\"] - res3[\"pred\"])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00239919122103193\n"
     ]
    }
   ],
   "source": [
    "print(np.average(res3.angle / 27))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.236913446913781\n"
     ]
    }
   ],
   "source": [
    "print(np.average(res3.dist / 27))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7040534467397166\n"
     ]
    }
   ],
   "source": [
    "print(np.average(res3.metric / 27))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
